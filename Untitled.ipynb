{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa25044e-be81-46e7-9a69-1073cf57b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "import psycopg2 as psql\n",
    "import creds\n",
    "\n",
    "dataFolder = './data/station_normals/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bf430-c364-4444-b076-8b9dec0dba11",
   "metadata": {},
   "source": [
    "* 1981-2010\n",
    "    * [hourly](https://www.ncei.noaa.gov/data/normals-hourly/1981-2010/archive/), [daily](https://www.ncei.noaa.gov/data/normals-daily/1981-2010/archive/), [monthly](https://www.ncei.noaa.gov/data/normals-monthly/1981-2010/archive/)\n",
    "    \n",
    "* 1991-2020\n",
    "    * [hourly](https://www.ncei.noaa.gov/data/normals-hourly/1991-2020/archive/), [daily](https://www.ncei.noaa.gov/data/normals-daily/1991-2020/archive/), [monthly](https://www.ncei.noaa.gov/data/normals-monthly/1991-2020/archive/)\n",
    "    \n",
    "* 2006-2020\n",
    "    * [hourly](https://www.ncei.noaa.gov/data/normals-hourly/2006-2020/archive/), [daily](https://www.ncei.noaa.gov/data/normals-daily/2006-2020/archive/), [monthly](https://www.ncei.noaa.gov/data/normals-monthly/2006-2020/archive/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ae24fa-f2b0-4b0d-a936-6032ac9df0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to grab the tar files for each of the normal variations:\n",
    "def get_tar_extract(main_url, normal_type, normal_period):\n",
    "    \n",
    "    normalFolder = f'{dataFolder}{normal_period}/{normal_type}/'\n",
    "    \n",
    "    if os.path.exists(f'{normalFolder}station_files'):\n",
    "        print(f'{normal_period} {normal_type} already downloaded...')\n",
    "        return normalFolder\n",
    "        \n",
    "    base_url = f'{main_url}{normal_type}/{normal_period}/archive/'\n",
    "   \n",
    "    if normal_period == '1981-2010':\n",
    "        tar_url = f'{base_url}{normal_type}.tar.gz'\n",
    "    else:\n",
    "        html_page = req.urlopen(base_url)\n",
    "        soup = bsoup(html_page, \"html.parser\")\n",
    "        for link in soup.findAll('a'):\n",
    "            if 'station' in  link.text:\n",
    "                tar_url = f'{base_url}{link.text}'\n",
    "        \n",
    "    ftpstream = req.urlopen(tar_url)\n",
    "    file = tarfile.open(fileobj = ftpstream, mode = 'r|gz')\n",
    "    \n",
    "    print(f'Getting {normal_period} normals...')\n",
    "    print(f'*** {normal_type} extracting to {normalFolder}station_files ***')\n",
    "    file.extractall(f'{normalFolder}station_files')\n",
    "    print(f'*** {normal_type} extraction completed ***')\n",
    "    return normalFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_Files(combined_file, files_toCombine):\n",
    "    if os.path.exists(combined_file):\n",
    "        return print(f'{combined_file} exists...')\n",
    "    \n",
    "    with open(combined_file, 'w') as outfile:\n",
    "        initial = 1\n",
    "        for file in files_toCombine:\n",
    "            with open(file, 'r') as infile:\n",
    "                header = infile.readline()\n",
    "                if initial:\n",
    "                    outfile.write(f'{header}')\n",
    "                    initial = 0\n",
    "                outfile.write(infile.read())\n",
    "    return print(f'{combined_file} created...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20dddc34-1e3e-44f6-a355-46d6f3b846c0",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1981-2010 normals-hourly already downloaded...\n1981-2010 normals-daily already downloaded...\n1981-2010 normals-monthly already downloaded...\n1991-2020 normals-hourly already downloaded...\n1991-2020 normals-daily already downloaded...\n1991-2020 normals-monthly already downloaded...\n2006-2020 normals-hourly already downloaded...\n2006-2020 normals-daily already downloaded...\n2006-2020 normals-monthly already downloaded...\n./txt_files/all-stations.csv exists...\n"
     ]
    }
   ],
   "source": [
    "# get climate normals files and creates master station list\n",
    "\n",
    "normal_periods = ['1981-2010','1991-2020','2006-2020']\n",
    "normal_types = ['normals-hourly','normals-daily', 'normals-monthly']\n",
    "main_url = 'https://www.ncei.noaa.gov/data/'\n",
    "\n",
    "climates = {}\n",
    "file_list =[]\n",
    "for normal_period in normal_periods:\n",
    "    climates[normal_period] = {}\n",
    "    for normal_type in normal_types:\n",
    "        location = get_tar_extract(main_url, normal_type, normal_period)\n",
    "        climates[normal_period][normal_type] = {'location': location, 'inventory_file': f'{location}station-inventory.csv'}\n",
    "        file_list.append(f'{location}station-inventory.csv')\n",
    "    \n",
    "mainInventory_file = f'./txt_files/all-stations.csv'  \n",
    "combine_Files(mainInventory_file, file_list)\n",
    "del file_list\n",
    "# opens massive csv file into pandas DataFrame to drop duplicate rows and then resaves csv file\n",
    "# note some station id values may be repeated due to other fields being different\n",
    "df = pd.read_csv(mainInventory_file)\n",
    "df = df.drop_duplicates(keep='last').sort_values(by=['state', 'name']).reset_index(drop=True)\n",
    "df.wmo_id = df.wmo_id.astype(dtype='Int64')\n",
    "df.to_csv(mainInventory_file,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  STATION      DATE             LATITUDE  LONGITUDE  ELEVATION  \\\n",
       "0  AQW00061705  01-01T00:00:00 -14.33056 -170.71361  3.7         \n",
       "1  AQW00061705  01-01T01:00:00 -14.33056 -170.71361  3.7         \n",
       "2  AQW00061705  01-01T02:00:00 -14.33056 -170.71361  3.7         \n",
       "3  AQW00061705  01-01T03:00:00 -14.33056 -170.71361  3.7         \n",
       "4  AQW00061705  01-01T04:00:00 -14.33056 -170.71361  3.7         \n",
       "\n",
       "  NAME                                              HLY-CLDH-NORMAL  \\\n",
       "0  PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ  154.0             \n",
       "1  PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ  153.0             \n",
       "2  PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ  151.0             \n",
       "3  PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ  149.0             \n",
       "4  PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ  147.0             \n",
       "\n",
       "  HLY-CLDH-NORMAL_ATTRIBUTES  HLY-CLOD-PCTBKN HLY-CLOD-PCTBKN_ATTRIBUTES  ...  \\\n",
       "0  P                          383              C                          ...   \n",
       "1  C                          363              C                          ...   \n",
       "2  C                          380              C                          ...   \n",
       "3  C                          354              C                          ...   \n",
       "4  C                          382              C                          ...   \n",
       "\n",
       "   HLY-WIND-2NDPCT HLY-WIND-2NDPCT_ATTRIBUTES  HLY-WIND-AVGSPD  \\\n",
       "0  169.0            S                          94.0              \n",
       "1  164.0            C                          91.0              \n",
       "2  173.0            C                          89.0              \n",
       "3  175.0            C                          89.0              \n",
       "4  181.0            C                          90.0              \n",
       "\n",
       "  HLY-WIND-AVGSPD_ATTRIBUTES  HLY-WIND-PCTCLM HLY-WIND-PCTCLM_ATTRIBUTES  \\\n",
       "0  S                          86.0             S                           \n",
       "1  C                          62.0             C                           \n",
       "2  C                          74.0             C                           \n",
       "3  C                          71.0             C                           \n",
       "4  C                          78.0             C                           \n",
       "\n",
       "   HLY-WIND-VCTDIR HLY-WIND-VCTDIR_ATTRIBUTES  HLY-WIND-VCTSPD  \\\n",
       "0  37.0             S                          33.0              \n",
       "1  43.0             C                          33.0              \n",
       "2  49.0             C                          34.0              \n",
       "3  40.0             C                          30.0              \n",
       "4  46.0             C                          32.0              \n",
       "\n",
       "  HLY-WIND-VCTSPD_ATTRIBUTES  \n",
       "0  S                          \n",
       "1  C                          \n",
       "2  C                          \n",
       "3  C                          \n",
       "4  C                          \n",
       "\n",
       "[5 rows x 58 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th></th>\n      <th>STATION</th>\n      <th>DATE</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>ELEVATION</th>\n      <th>NAME</th>\n      <th>HLY-CLDH-NORMAL</th>\n      <th>HLY-CLDH-NORMAL_ATTRIBUTES</th>\n      <th>HLY-CLOD-PCTBKN</th>\n      <th>HLY-CLOD-PCTBKN_ATTRIBUTES</th>\n      <th>...</th>\n      <th>HLY-WIND-2NDPCT</th>\n      <th>HLY-WIND-2NDPCT_ATTRIBUTES</th>\n      <th>HLY-WIND-AVGSPD</th>\n      <th>HLY-WIND-AVGSPD_ATTRIBUTES</th>\n      <th>HLY-WIND-PCTCLM</th>\n      <th>HLY-WIND-PCTCLM_ATTRIBUTES</th>\n      <th>HLY-WIND-VCTDIR</th>\n      <th>HLY-WIND-VCTDIR_ATTRIBUTES</th>\n      <th>HLY-WIND-VCTSPD</th>\n      <th>HLY-WIND-VCTSPD_ATTRIBUTES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AQW00061705</td>\n      <td>01-01T00:00:00</td>\n      <td>-14.33056</td>\n      <td>-170.71361</td>\n      <td>3.7</td>\n      <td>PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ</td>\n      <td>154.0</td>\n      <td>P</td>\n      <td>383</td>\n      <td>C</td>\n      <td>...</td>\n      <td>169.0</td>\n      <td>S</td>\n      <td>94.0</td>\n      <td>S</td>\n      <td>86.0</td>\n      <td>S</td>\n      <td>37.0</td>\n      <td>S</td>\n      <td>33.0</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AQW00061705</td>\n      <td>01-01T01:00:00</td>\n      <td>-14.33056</td>\n      <td>-170.71361</td>\n      <td>3.7</td>\n      <td>PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ</td>\n      <td>153.0</td>\n      <td>C</td>\n      <td>363</td>\n      <td>C</td>\n      <td>...</td>\n      <td>164.0</td>\n      <td>C</td>\n      <td>91.0</td>\n      <td>C</td>\n      <td>62.0</td>\n      <td>C</td>\n      <td>43.0</td>\n      <td>C</td>\n      <td>33.0</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AQW00061705</td>\n      <td>01-01T02:00:00</td>\n      <td>-14.33056</td>\n      <td>-170.71361</td>\n      <td>3.7</td>\n      <td>PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ</td>\n      <td>151.0</td>\n      <td>C</td>\n      <td>380</td>\n      <td>C</td>\n      <td>...</td>\n      <td>173.0</td>\n      <td>C</td>\n      <td>89.0</td>\n      <td>C</td>\n      <td>74.0</td>\n      <td>C</td>\n      <td>49.0</td>\n      <td>C</td>\n      <td>34.0</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AQW00061705</td>\n      <td>01-01T03:00:00</td>\n      <td>-14.33056</td>\n      <td>-170.71361</td>\n      <td>3.7</td>\n      <td>PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ</td>\n      <td>149.0</td>\n      <td>C</td>\n      <td>354</td>\n      <td>C</td>\n      <td>...</td>\n      <td>175.0</td>\n      <td>C</td>\n      <td>89.0</td>\n      <td>C</td>\n      <td>71.0</td>\n      <td>C</td>\n      <td>40.0</td>\n      <td>C</td>\n      <td>30.0</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AQW00061705</td>\n      <td>01-01T04:00:00</td>\n      <td>-14.33056</td>\n      <td>-170.71361</td>\n      <td>3.7</td>\n      <td>PAGO PAGO WEATHER SERVICE OFFICE AIRPORT, AS AQ</td>\n      <td>147.0</td>\n      <td>C</td>\n      <td>382</td>\n      <td>C</td>\n      <td>...</td>\n      <td>181.0</td>\n      <td>C</td>\n      <td>90.0</td>\n      <td>C</td>\n      <td>78.0</td>\n      <td>C</td>\n      <td>46.0</td>\n      <td>C</td>\n      <td>32.0</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 58 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "normal_period = '1981-2010'\n",
    "normal_type = 'normals-hourly'\n",
    "headerFile = f'./txt_files/csv_headers/headers-{normal_period}-{normal_type}.txt'\n",
    "reformatted_File = f'{climates[normal_period][normal_type][\"location\"]}test.csv'  \n",
    "\n",
    "headers = []\n",
    "with open(headerFile, 'r') as hfile:\n",
    "    lines = hfile.readlines()\n",
    "    for line in lines:\n",
    "        headers.append(line.strip('\\n'))\n",
    "     \n",
    "normal_files = Path(f'{climates[normal_period][normal_type][\"location\"]}station_files/').glob('*.csv')\n",
    "for normal_file in normal_files:\n",
    "    df = pd.read_csv(normal_file)\n",
    "    # if normal_period == '1981-2010':\n",
    "    #     dates_dict = format_date(df.DATE, '%m-%dT%X')\n",
    "    #     df = df.append(dates_dict, ignore_index=True)\n",
    "    # df = df.reindex(columns=headers)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    break\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "STATION                        0\n",
       "DATE                           0\n",
       "LATITUDE                       0\n",
       "LONGITUDE                      0\n",
       "ELEVATION                      0\n",
       "                              ..\n",
       "HLY-WIND-PCTCLM_ATTRIBUTES    88\n",
       "HLY-WIND-VCTDIR               88\n",
       "HLY-WIND-VCTDIR_ATTRIBUTES    88\n",
       "HLY-WIND-VCTSPD               88\n",
       "HLY-WIND-VCTSPD_ATTRIBUTES    88\n",
       "Length: 58, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date_series, format_IN):\n",
    "    temp = pd.to_datetime(date_series, format = format_IN)\n",
    "    dates = temp.apply(lambda x: x.strftime('%m-%d %H'))\n",
    "    months = temp.apply(lambda x: int(x.strftime('%m')))\n",
    "    days = temp.apply(lambda x: int(x.strftime('%d')))\n",
    "    hours = temp.apply(lambda x: int(x.strftime('%H')))\n",
    "    return {'DATE': dates, 'month': months, 'day': days, 'hour': hours}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   a  b  c\n0  1  2  3\n   b  da  c  a\n0  2 NaN  3  1\n"
     ]
    }
   ],
   "source": [
    "col = ['a','b','c']\n",
    "cols= ['b','da','c','a']\n",
    "a = pd.DataFrame({'a':[1],'b':[2],'c':[3]})\n",
    "print(a)\n",
    "b = a.reindex(columns=cols)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_periods = ['1981-2010','1991-2020','2006-2020']\n",
    "normal_types = ['normals-hourly','normals-daily', 'normals-monthly']\n",
    "\n",
    "for normal_period in normal_periods:\n",
    "    header_list =[]\n",
    "    for normal_type in normal_types:\n",
    "        combined_file = f'{climates[normal_period][normal_type][\"location\"]}{normal_type}-{normal_period}.csv'\n",
    "        files_location = f'{climates[normal_period][normal_type][\"location\"]}station_files/'\n",
    "        files_toCombine = Path(files_location).glob('*.csv')\n",
    "        # combine_Files(combined_file, files_toCombine)\n",
    "\n",
    "        for file in files_toCombine:\n",
    "            with open(file, 'r') as infile:\n",
    "                header_list.append([file.name, infile.readline()])\n",
    "\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connected: climate_normals_db\n"
     ]
    }
   ],
   "source": [
    "a = connect_db('climate_normals_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(db_Name):\n",
    "    try:\n",
    "        conn = psql.connect(\n",
    "                user=creds.USER,\n",
    "                password=creds.PASS,\n",
    "                host=creds.HOST,\n",
    "                port=creds.PORT,\n",
    "                database=db_Name\n",
    "                )\n",
    "    except psql.OperationalError as e:\n",
    "        print(f'There is no database named {db_Name}...')\n",
    "        create_db(db_Name)\n",
    "        return connect_db(db_Name)\n",
    "    else:\n",
    "        print(f'Connected: {db_Name}')\n",
    "        return conn\n",
    "        \n",
    "def create_db(db_Name):\n",
    "    conn = psql.connect(\n",
    "                user=creds.USER,\n",
    "                password=creds.PASS,\n",
    "                host=creds.HOST,\n",
    "                port=creds.PORT,\n",
    "                database='postgres'\n",
    "                )\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "    sql=f'CREATE database {db_Name}'\n",
    "\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except psql.errors.lookup('42P04'): #psql error code for duplicatedatabase\n",
    "        conn.close()\n",
    "        return print(f\"....Database: {db_Name} already exists....\")\n",
    "    else:\n",
    "        print(f'....Database: {db_Name} created....')      \n",
    "        conn.close()\n",
    "        return print(f\"....Database: {db_Name} created successfully....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "....Database: climate_normals_db already exists....\n"
     ]
    }
   ],
   "source": [
    "create_db('climate_normals_db')"
   ]
  },
  {
   "source": [
    "# 1981-2010 headers\n",
    "#RRR-EEEE-SSSSSS[-CCCCCCC]#\n",
    "#RRR\n",
    "reporting_period = {\n",
    "    'ann': 'annual',\n",
    "    'djf': 'December, January, February',\n",
    "    'dly': 'daily',\n",
    "    'hly': 'hourly',\n",
    "    'jja': 'June, July, August',\n",
    "    'mam': 'March, April, May',\n",
    "    'mly': 'monthly',\n",
    "    'mtd': 'month-to-date',\n",
    "    'rtp': 'return periods',\n",
    "    'son': 'September, October, November',\n",
    "    'ytd': 'year-to-date'\n",
    "}\n",
    "#metorological element, EEEE\n",
    "met_elem = {\n",
    "    'cldd': 'cooling degree days',\n",
    "    'cldh': 'cooling degree hours',\n",
    "    'clod': 'clouds',\n",
    "    'dewp': 'dew point temperature',\n",
    "    'dutr': 'diurnal temperature range',\n",
    "    'hidx': 'heat index',\n",
    "    'htdd': 'heating degree days',\n",
    "    'htdh': 'heating degree hours',\n",
    "    'prcp': 'precipitation',\n",
    "    'pres': 'sea level pressure',\n",
    "    'snow': 'snowfall',\n",
    "    'snwd': 'snow depth',\n",
    "    'tavg': 'daily mean temperature (average of tmax and tmin)',\n",
    "    'temp': 'temperature',\n",
    "    'tmax': 'daily maximum temperature',\n",
    "    'tmin': 'daily minimum temperature',\n",
    "    'wchl': 'wind chill',\n",
    "    'wind': 'wind'\n",
    "}\n",
    "\n",
    "#Statistic, SSSSSS\n",
    "statistic = {\n",
    "    '10pctl': 'Climatological 10th percentile',\n",
    "    '1stdir': 'Prevailing Wind Direction',\n",
    "    '1stpct': 'Prevailing Wind Percentage',\n",
    "    '2nddir': 'Secondary Wind Direction',\n",
    "    '2ndpct': 'Secondary Wind Percentage',\n",
    "    '25pctl': 'Climatological 25th percentile',\n",
    "    '50pctl': 'Climatological 50th percentile',\n",
    "    '75pctl': 'Climatological 75th percentile',\n",
    "    '90pctl': 'Climatological 90th percentile',\n",
    "    'avgnds': 'Average Number of Days (followed by a condition)',\n",
    "    'avgspd': 'Average Wind Speed',\n",
    "    'baseNN': 'Average of base NN (other than 65F) Heating or Cooling Degree Days\n",
    "    'normal': 'Climatological Average',\n",
    "    'pctall': 'Probability of Occurrence (followed by a condition)',\n",
    "    'pctbkn': 'Percent Broken (clouds)',\n",
    "    'pctclm': 'Percent Calm (winds)',\n",
    "    'pctclr': 'Percent Clear (clouds)',\n",
    "    'pctfew': 'Percent Few (clouds)',\n",
    "    'pctovc': 'Percent Overcast (clouds)',\n",
    "    'pctsct': 'Percent Scattered (clouds)',\n",
    "    'vctdir': 'Mean Wind Vector Direction',\n",
    "    'vctspd': 'Mean Wind Vector Magnitude'\n",
    "}\n",
    "\n",
    "#Condition, -CCCCCCC\n",
    "condition = {\n",
    "    'geNNNhi' : 'greater than or equal to NNN hundredths of inches NNN can be 001,010,050,100 (for precipitation)', \n",
    "    'geNNNti' : 'greater than or equal to NNN tenths of inches NNN can be 001,010,030,050,100 (for snowfall)',\n",
    "    'geNNNwi' : 'greater than or equal to NNN whole inches NNN can be 001,003,005,010 (for snow depth)',\n",
    "    'grthNNN' : 'greater than or equal to NNN whole degrees Fahrenheit NNN can be 040,050,060,070,080,090,100',\n",
    "    'lsthNNN' : 'less than or equal to NNN whole degrees Fahrenheit NNN can be 000,010,020,032,040,050,060'\n",
    "}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd08829f2f28fb4fe9df99e8c305ffe937ba372ff45bcdf063cdbd318f5788220f1",
   "display_name": "Python 3.9.2 64-bit ('Climate-Normals': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}